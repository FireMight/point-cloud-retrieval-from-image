{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 558.7684326171875\n",
      "Epoch 0 Accuracy 0.3333333333333333\n",
      "Loss 800.04248046875\n",
      "Epoch 1 Accuracy 0.3333333333333333\n",
      "Loss 473.3464050292969\n",
      "Epoch 2 Accuracy 0.3333333333333333\n",
      "Loss 638.9999389648438\n",
      "Epoch 3 Accuracy 0.3333333333333333\n",
      "Loss 247.45834350585938\n",
      "Epoch 4 Accuracy 0.6666666666666666\n",
      "Loss 184.34637451171875\n",
      "Epoch 5 Accuracy 0.6666666666666666\n",
      "Loss 111.52462005615234\n",
      "Epoch 6 Accuracy 0.6666666666666666\n",
      "Loss 43.065757751464844\n",
      "Epoch 7 Accuracy 0.3333333333333333\n",
      "Loss 254.51365661621094\n",
      "Epoch 8 Accuracy 0.6666666666666666\n",
      "Loss 69.72186279296875\n",
      "Epoch 9 Accuracy 0.6666666666666666\n",
      "Loss 22.808025360107422\n",
      "Epoch 10 Accuracy 0.3333333333333333\n",
      "Loss 21.8028564453125\n",
      "Epoch 11 Accuracy 0.6666666666666666\n",
      "Loss 217.69015502929688\n",
      "Epoch 12 Accuracy 0.6666666666666666\n",
      "Loss 85.88023376464844\n",
      "Epoch 13 Accuracy 0.6666666666666666\n",
      "Loss 134.81155395507812\n",
      "Epoch 14 Accuracy 0.6666666666666666\n",
      "Loss 161.8106689453125\n",
      "Epoch 15 Accuracy 0.6666666666666666\n",
      "Loss 423.9128112792969\n",
      "Epoch 16 Accuracy 0.6666666666666666\n",
      "Loss 359.9976501464844\n",
      "Epoch 17 Accuracy 0.6666666666666666\n",
      "Loss 195.20152282714844\n",
      "Epoch 18 Accuracy 0.6666666666666666\n",
      "Loss 113.89630126953125\n",
      "Epoch 19 Accuracy 0.6666666666666666\n",
      "Loss 132.19424438476562\n",
      "Epoch 20 Accuracy 0.6666666666666666\n",
      "Loss 55.162193298339844\n",
      "Epoch 21 Accuracy 0.3333333333333333\n",
      "Loss 328.5806884765625\n",
      "Epoch 22 Accuracy 0.3333333333333333\n",
      "Loss 406.51409912109375\n",
      "Epoch 23 Accuracy 0.3333333333333333\n",
      "Loss 476.4619140625\n",
      "Epoch 24 Accuracy 0.3333333333333333\n",
      "Loss 519.10107421875\n",
      "Epoch 25 Accuracy 0.3333333333333333\n",
      "Loss 458.95648193359375\n",
      "Epoch 26 Accuracy 0.3333333333333333\n",
      "Loss 466.62933349609375\n",
      "Epoch 27 Accuracy 0.3333333333333333\n",
      "Loss 338.17974853515625\n",
      "Epoch 28 Accuracy 0.3333333333333333\n",
      "Loss 264.3119201660156\n",
      "Epoch 29 Accuracy 0.3333333333333333\n",
      "Loss 196.8484344482422\n",
      "Epoch 30 Accuracy 0.3333333333333333\n",
      "Loss 112.20262145996094\n",
      "Epoch 31 Accuracy 0.3333333333333333\n",
      "Loss 19.192626953125\n",
      "Epoch 32 Accuracy 1.0\n",
      "1.3738480806350708 1.2783972024917603 1\n",
      "Correct\n",
      "1.3678785562515259 1.3840229511260986 0\n",
      "Correct\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "import netvlad.netvlad as netvlad\n",
    "import pointnet.pointnet.model as pointnet\n",
    "\n",
    "net_vlad_path = 'models/vgg16_netvlad_checkpoint/checkpoints/checkpoint.pth.tar'\n",
    "img_data_path = 'data/oxford/img/'\n",
    "pcl_data_path = 'data/oxford/pcl/'\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Triplet loss\n",
    "    Takes embeddings of an anchor sample, a positive sample and a negative sample\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin = 1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative, size_average=True):\n",
    "        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
    "        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
    "        losses = nn.functional.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean() if size_average else losses.sum()\n",
    "\n",
    "#appends a FC linear to transform output descriptor to appropriate dimenstion\n",
    "#TODO: make a nice wrapper for NetVLAD\n",
    "class ModifiedNetVLAD(nn.Module):\n",
    "    def __init__(self, model,out_features):\n",
    "        super(ModifiedNetVLAD, self).__init__()\n",
    "        self.vlad = model\n",
    "        self.fc = nn.Linear(32768, out_features)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.vlad.pool(self.vlad.encoder(x))\n",
    "        x = x.view((x.shape[0],32768))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def load_netvlad(checkpoint_path):\n",
    "    encoder_dim = 512\n",
    "    encoder = models.vgg16(pretrained=False)\n",
    "    layers = list(encoder.features.children())[:-2]\n",
    "    encoder = nn.Sequential(*layers)    \n",
    "    model = nn.Module()\n",
    "    model.add_module('encoder', encoder)\n",
    "    vlad_layer = netvlad.NetVLAD(num_clusters=64, dim=encoder_dim, vladv2=False)\n",
    "    model.add_module('pool',vlad_layer)\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path,map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#overfit to single sample (single image, single pcl); descriptors should be exactly equal\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    #set up models\n",
    "    \n",
    "    #input: image, output 32K desc\n",
    "    img_net = load_netvlad(net_vlad_path)\n",
    "    #append FC layer to reduce to 1K desc\n",
    "    img_net = ModifiedNetVLAD(img_net,1024)\n",
    "    \n",
    "    #input: pcl. output 1K desc\n",
    "    pcl_net = pointnet.PointNetfeat(True,True)\n",
    "    \n",
    "    transform = torchvision.transforms.Compose([torchvision.transforms.Resize([240,320]),\n",
    "                                                torchvision.transforms.ToTensor()])\n",
    "    img_dataset = torchvision.datasets.ImageFolder(root=img_data_path,transform=torchvision.transforms.ToTensor())\n",
    "    img_dataset, test_dataset = torch.utils.data.random_split(img_dataset,[int(0.8*len(img_dataset)),len(img_dataset) - int(0.8*len(img_dataset))])\n",
    "    img_loader = torch.utils.data.DataLoader(img_dataset,shuffle=True)\n",
    "    \n",
    "    pcl0 = np.fromfile('data/oxford/pcl/oxford_2014-12-12_0.pcl').reshape(1,3,8192)\n",
    "    pcl1 = np.fromfile('data/oxford/pcl/oxford_2014-12-12_1.pcl').reshape(1,3,8192)\n",
    "    pcl =  np.append(pcl0,pcl1,0)\n",
    "    pcl = torch.from_numpy(pcl).float()\n",
    "    pcl.requires_grad_(False)\n",
    "    \n",
    "    \n",
    "    img_net.to(device)\n",
    "    \n",
    "    pcl_net.to(device)\n",
    "    \n",
    "    img_net.train()\n",
    "    pcl_net.train()\n",
    "    optim = torch.optim.Adam(chain(img_net.parameters(),pcl_net.parameters()),lr=1e-4)\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    tl=TripletLoss(5);\n",
    "    #train\n",
    "    for i in range(50):\n",
    "        loss = 0\n",
    "        img = img_dataset[0][0].view(1,3,240,320)\n",
    "        for j in range(1,len(img_dataset)):\n",
    "            img = torch.cat((img,img_dataset[j][0].view(1,3,240,320)),0)\n",
    "        img.requires_grad_(False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = img_net.vlad.pool(img_net.vlad.encoder(img.to(device)))\n",
    "            x = x.view((x.shape[0],32768))\n",
    "       \n",
    "        img_desc = img_net.fc(x)\n",
    "            \n",
    "        pcl_desc,_,_ = pcl_net(pcl.to(device))\n",
    "        pos = pcl_desc[img_dataset[0][1],:].view(1,1024)\n",
    "        neg = pcl_desc[img_dataset[0][1]-1,:].view(1,1024)\n",
    "        for j in range(1,len(img_dataset)):\n",
    "            t = img_dataset[j][1]\n",
    "            pos = torch.cat((pos,pcl_desc[t,:].view(1,1024)),0)\n",
    "            neg = torch.cat((neg,pcl_desc[t-1,:].view(1,1024)),0)\n",
    "            \n",
    "        loss = tl(img_desc,pos,neg,True)\n",
    "        print(\"Loss {}\".format(loss))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            pcl_desc,_,_ = pcl_net(pcl.to(device))\n",
    "            num_correct = 0\n",
    "            \n",
    "            for img,t in img_dataset:\n",
    "                img = img.view(1,3,240,320)\n",
    "                img_desc = img_net(img.to(device))\n",
    "                d0 = torch.nn.functional.mse_loss(img_desc,pcl_desc[0,:].view(1,1024))\n",
    "                d1 = torch.nn.functional.mse_loss(img_desc,pcl_desc[1,:].view(1,1024))\n",
    "                if(t==0 and d0<d1) or (t==1 and d0>d1):\n",
    "                    num_correct+=1\n",
    "            \n",
    "            print(\"Epoch {} Accuracy {}\".format(i,num_correct/len(img_dataset)))\n",
    "            if(num_correct==len(img_dataset)):\n",
    "                break\n",
    "            \n",
    "    #store descriptors\n",
    "    optim.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        pcl_desc,_,_ = pcl_net(pcl.to(device))\n",
    "        \n",
    "        for img,t in test_dataset:\n",
    "            img = img.view(1,3,240,320)\n",
    "            img_desc = img_net(img.to(device))\n",
    "            d0 = torch.nn.functional.mse_loss(img_desc,pcl_desc[0,:].view(1,1024))\n",
    "            d1 = torch.nn.functional.mse_loss(img_desc,pcl_desc[1,:].view(1,1024))\n",
    "            print(\"{} {} {}\".format(d0,d1,t))\n",
    "            if(t==0 and d0<d1) or (t==1 and d0>d1):\n",
    "                print(\"Correct\")\n",
    "            else:\n",
    "                print(\"Wrong\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
