{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_pcl_submaps.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FireMight/point-cloud-retrieval-from-image/blob/master/generate_pcl_submaps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jejTZ5WVVBjX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "ff42c80e-4886-435c-836a-670d78bf40fc"
      },
      "source": [
        "# First time\n",
        "%cd /content\n",
        "!git clone https://github.com/FireMight/point-cloud-retrieval-from-image.git\n",
        "%cd /content/point-cloud-retrieval-from-image\n",
        "!git submodule update --init --recursive\n",
        "%cd .."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'point-cloud-retrieval-from-image' already exists and is not an empty directory.\n",
            "/content/point-cloud-retrieval-from-image\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx1Ms3bhyyFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "11b2a56a-ae69-432a-b634-cdfbec1e2d4c"
      },
      "source": [
        "# Pull repository\n",
        "%cd /content/point-cloud-retrieval-from-image\n",
        "!git pull --recurse-submodules\n",
        "%cd .."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/point-cloud-retrieval-from-image\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 7 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), done.\n",
            "From https://github.com/FireMight/point-cloud-retrieval-from-image\n",
            "   2667a80..7302be0  master     -> origin/master\n",
            "Fetching submodule netvlad\n",
            "Fetching submodule pointnet\n",
            "Updating 2667a80..7302be0\n",
            "Fast-forward\n",
            " data/oxford/robotcar-dataset-sdk/python/build_pointcloud.py | 2 \u001b[32m++\u001b[m\n",
            " 1 file changed, 2 insertions(+)\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3oTLMRcUHuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import sys\n",
        "import numpy as np\n",
        "from scipy.spatial.transform import Rotation\n",
        "from google.colab import drive\n",
        "\n",
        "sdk_dir = '/content/point-cloud-retrieval-from-image/data/oxford/robotcar-dataset-sdk'\n",
        "sys.path.insert(0, sdk_dir + '/python')\n",
        "import build_pointcloud as sdk_pcl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Y3DswOOhn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "83fbd688-7096-453c-aad2-07a2b8367a94"
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "project_dir = '/content/drive/My Drive/ADL4CV'\n",
        "\n",
        "run_id = 'reference'\n",
        "data_dir = project_dir + '/downloads/oxford_dataset/' + run_id\n",
        "lms_dir = data_dir + '/lms_front'\n",
        "lms_timestamps_file = data_dir + '/lms_front.timestamps'\n",
        "gps_dir = data_dir + '/gps'\n",
        "ins_data_file = gps_dir + '/ins.csv'\n",
        "extrinsics_dir = sdk_dir + '/extrinsics'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLvqzeW_OxId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PointcloudLoader():\n",
        "    def __init__(self):\n",
        "        self.trajectory_ned = None\n",
        "        self.pointcloud_ned = None\n",
        "        self.subset_split = None\n",
        "    \n",
        "    def load_ned_trajectory(self, subset_split=None):\n",
        "        # Get start and end timestamp of LIDAR measurements\n",
        "        print('Get start and end time of LIADR measurements...')\n",
        "        with open(lms_timestamps_file) as ts_file:\n",
        "            start_time = int(next(ts_file).split(' ')[0])\n",
        "            for end_time in ts_file:\n",
        "                continue\n",
        "            end_time = int(end_time.split(' ')[0])\n",
        "        print('Done!')\n",
        "\n",
        "        # Check if NED trajectory has already been computed\n",
        "        trajectory_file = gps_dir + '/ned_trajectory_ins_{}.npy'.format(run_id)\n",
        "        print('Search for precomputed NED trajectory ' + trajectory_file + '...')\n",
        "\n",
        "        try:\n",
        "            self.trajectory_ned = np.load(trajectory_file)\n",
        "            print('Done!')\n",
        "        except:\n",
        "            # Get trajectory corresponding to LIDAR data\n",
        "            print('Not found! Create NED trajectory from INS data...')\n",
        "            self.trajectory_ned = np.empty((7,0))\n",
        "            with open(ins_data_file, 'r') as ins_file:\n",
        "                reader = csv.DictReader(ins_file)\n",
        "                for row in reader:\n",
        "                    if int(row['timestamp']) > end_time:\n",
        "                        break\n",
        "                    if int(row['timestamp']) < start_time:\n",
        "                        continue\n",
        "                    ned_state = np.array([float(row['northing']),\n",
        "                                          float(row['easting']),\n",
        "                                          float(row['down']),\n",
        "                                          float(row['roll']),\n",
        "                                          float(row['pitch']),\n",
        "                                          float(row['yaw']),\n",
        "                                          float(row['timestamp'])]).reshape(7,1)\n",
        "                    self.trajectory_ned = np.append(self.trajectory_ned, \n",
        "                                                    ned_state, axis=1)\n",
        "            print('Done! Trajectory with {} samples'.format(\n",
        "                                                  self.trajectory_ned.shape[1]))\n",
        "\n",
        "            # Save trajectory\n",
        "            print('Save NED trajectory to ' + trajectory_file + '...')\n",
        "            np.save(trajectory_file, self.trajectory_ned)\n",
        "            print('Done!')\n",
        "            \n",
        "        # If specified, use only a subset of the data\n",
        "        if subset_split is not None:\n",
        "            max_idx = int(self.trajectory_ned.shape[1] * subset_split)\n",
        "            print('WARNING: We use only the first {}% of the trajectory ({} measurements)'.\n",
        "                                                format(int(subset_split*100), max_idx))\n",
        "            self.trajectory_ned = self.trajectory_ned[:,:max_idx]\n",
        "            self.subset_split = subset_split\n",
        "            \n",
        "    def load_ned_pointcloud(self):\n",
        "        # Check if NED pointcloud has already been computed\n",
        "        if self.subset_split is None:\n",
        "            pointcloud_file = lms_dir + '/ned_pointcloud_{}.npy'.format(run_id)\n",
        "        else:\n",
        "            pointcloud_file = lms_dir + '/ned_pointcloud_{}_{}percent.npy'.format(\n",
        "                                             run_id, int(self.subset_split*100))\n",
        "        print('Search for precomputed NED pointcloud ' + pointcloud_file + '...')\n",
        "\n",
        "        try:\n",
        "            self.pointcloud_ned = np.load(pointcloud_file)\n",
        "            print('Done!')\n",
        "        except:\n",
        "            # Construct pointcloud from lms measurements\n",
        "            print('Not found! Create pointcloud in vehicle reference system from LMS data...')\n",
        "            \n",
        "            start_time = self.trajectory_ned[6,0]\n",
        "            end_time = self.trajectory_ned[6,-1]\n",
        "\n",
        "            # Build pointcloud in vehicle reference frame\n",
        "            pointcloud_veh, _ = sdk_pcl.build_pointcloud(lms_dir, ins_data_file, \n",
        "                                                         extrinsics_dir, \n",
        "                                                         start_time, end_time)\n",
        "            print('Done!')\n",
        "            print('Transform pointcloud to NED system...')\n",
        "\n",
        "            # Transform pointlcoud to NED system\n",
        "            state_first_frame = self.trajectory_ned[:,0].flatten()\n",
        "            self.pointcloud_ned = self.pcl_trafo(pointcloud_veh, \n",
        "                                            trans_newref=state_first_frame[:3], \n",
        "                                            rot=state_first_frame[3:])\n",
        "            print('Done!')            \n",
        "            \n",
        "\n",
        "            # Save pointcloud\n",
        "            print('Save NED pointcloud to ' + pointcloud_file + '...')\n",
        "            np.save(pointcloud_file, self.pointcloud_ned)\n",
        "            print('Done!')\n",
        "            \n",
        "    def generate_submaps(self, length, spacing, width=None):\n",
        "        # Create directory and metadata csv file\n",
        "        submap_dir = data_dir + '/submaps_{}m'.format(int(length))\n",
        "        if not os.path.isdir(submap_dir):\n",
        "            os.mkdir(submap_dir)\n",
        "        \n",
        "        metadata_fieldnames = ['seg_idx', \n",
        "                               'timestamp_start',\n",
        "                               'northing_start',\n",
        "                               'easting_start',\n",
        "                               'down_start',\n",
        "                               'heading_start', \n",
        "                               'timestamp_center',\n",
        "                               'northing_center',\n",
        "                               'easting_center',\n",
        "                               'down_center',\n",
        "                               'heading_center']\n",
        "        metadata_csv = submap_dir + '/metadata.csv'\n",
        "        with open(metadata_csv, 'w') as outcsv:\n",
        "            writer = csv.DictWriter(outcsv, metadata_fieldnames)\n",
        "            writer.writeheader()\n",
        "        \n",
        "        # Walk along trajectory and create equally spaced submaps        \n",
        "        i_start = 0\n",
        "        segment_idx = 0\n",
        "        while True:\n",
        "            # Find center point and check if route is fully traversed\n",
        "            i_center = None\n",
        "            end_of_route = True\n",
        "            dist_to_end = length\n",
        "            prev_pos = self.trajectory_ned[:3,i_start]\n",
        "            for i in range(i_start+1, self.trajectory_ned.shape[1]):\n",
        "                curr_pos = self.trajectory_ned[:3,i]\n",
        "                dist_to_end -= np.linalg.norm(prev_pos - curr_pos)\n",
        "                prev_pos = curr_pos\n",
        "\n",
        "                if dist_to_end < length / 2 and i_center is None:\n",
        "                    i_center = i\n",
        "\n",
        "                if dist_to_end < 0:\n",
        "                    end_of_route = False\n",
        "                    break\n",
        "\n",
        "            # End if there fits no submap within the remaining trajectory\n",
        "            if end_of_route:\n",
        "                print('End of trajectory reached')\n",
        "                break\n",
        "\n",
        "\n",
        "            submap = self.get_pcl_submap(i_center, length, alignment='trajectory',\n",
        "                                         width=width)\n",
        "\n",
        "            submap = submap[:3,:]\n",
        "            # Removed the code below after problems with PCL\n",
        "            # Subtract center vector before saving in float32 format to keep precision\n",
        "            #center_pos = self.trajectory_ned[:3,i_center]\n",
        "            #center_pos = center_pos[:, np.newaxis]\n",
        "            #submap = submap - center_pos\n",
        "\n",
        "            # Save raw pointcloud for preprocessing with PCL later\n",
        "            submap_file = submap_dir + '/submap_{}.rawpcl'.format(segment_idx)\n",
        "            #submap.astype('float32').tofile(submap_file)\n",
        "            submap.tofile(submap_file)\n",
        "\n",
        "            # Save metadata\n",
        "            with open(metadata_csv, 'a') as outcsv:\n",
        "                writer = csv.DictWriter(outcsv,fieldnames=metadata_fieldnames)\n",
        "                writer.writerow({'seg_idx' : segment_idx, \n",
        "                                 'timestamp_start' : int(self.trajectory_ned[6,i_start]), \n",
        "                                 'northing_start' : self.trajectory_ned[0,i_start],\n",
        "                                 'easting_start' : self.trajectory_ned[1,i_start],\n",
        "                                 'down_start' : self.trajectory_ned[2,i_start],\n",
        "                                 'heading_start' : self.trajectory_ned[5,i_start],\n",
        "                                 'timestamp_center' : int(self.trajectory_ned[6,i_center]),\n",
        "                                 'northing_center' : self.trajectory_ned[0,i_center],\n",
        "                                 'easting_center' : self.trajectory_ned[1,i_center],\n",
        "                                 'down_center' : self.trajectory_ned[2,i_center],\n",
        "                                 'heading_center' : self.trajectory_ned[5,i_center]})\n",
        "\n",
        "            # Find next start index\n",
        "            dist_to_next = spacing\n",
        "            prev_pos = self.trajectory_ned[:3,i_start]\n",
        "            for i in range(i_start+1, self.trajectory_ned.shape[1]):\n",
        "                curr_pos = self.trajectory_ned[:3,i]\n",
        "                dist_to_next -= np.linalg.norm(prev_pos - curr_pos)\n",
        "                prev_pos = curr_pos\n",
        "\n",
        "                if dist_to_next < 0:\n",
        "                    i_start = i\n",
        "                    break\n",
        "            \n",
        "            print('Added submap {}'.format(segment_idx))\n",
        "            segment_idx += 1\n",
        "        \n",
        "        \n",
        "            \n",
        "    def get_pcl_submap(self, center_idx, coverage, alignment='north_east', \n",
        "                        width=None):\n",
        "        # Get center position on trajectory\n",
        "        center_pos = self.trajectory_ned[[0,1,2], center_idx]  \n",
        "\n",
        "        if alignment == 'north_east':\n",
        "            # Get all points with north and east coordinate within coverage/2\n",
        "            box_min = center_pos - coverage/2\n",
        "            box_max = center_pos + coverage/2\n",
        "            mask = np.array(np.logical_and(np.logical_and(self.pointcloud_ned[0,:]>=box_min[0],\n",
        "                                                          self.pointcloud_ned[0,:]<box_max[0]),\n",
        "                                           np.logical_and(self.pointcloud_ned[1,:]>=box_min[1], \n",
        "                                                          self.pointcloud_ned[1,:]<box_max[1]))).squeeze()\n",
        "            pcl_segment = self.pointcloud_ned[:,mask]\n",
        "\n",
        "        elif alignment == 'trajectory':        \n",
        "            # Bounding box length in trajectory direction, optional width orthogonal\n",
        "            center_heading = self.trajectory_ned[5, center_idx]\n",
        "\n",
        "            # Consider different width if specified, else use quadratic box\n",
        "            if width is None:\n",
        "                width = coverage\n",
        "\n",
        "            # Only considere points within certain range of the center point\n",
        "            r_max = np.sqrt(2 * pow(max(coverage, width)/2, 2))\n",
        "            r = np.linalg.norm(self.pointcloud_ned[:2,:] - center_pos[:2].reshape(2,1), \n",
        "                               axis=0)\n",
        "\n",
        "            pcl_ned = self.pointcloud_ned[:, r < r_max]\n",
        "\n",
        "            # Rotate pointcloud into bounding box reference system.\n",
        "            pcl_bb = self.pcl_trafo(pcl_ned, trans_oldref=-center_pos, \n",
        "                                    rot=np.array([0, 0, -center_heading]))\n",
        "\n",
        "            # Get extend of bounding box\n",
        "            box_max = np.array([coverage/2, width/2, 0])\n",
        "            box_min = -1 * box_max\n",
        "\n",
        "            mask = np.array(np.logical_and(np.logical_and(pcl_bb[0,:]>=box_min[0],\n",
        "                                                          pcl_bb[0,:]<box_max[0]),\n",
        "                                           np.logical_and(pcl_bb[1,:]>=box_min[1], \n",
        "                                                          pcl_bb[1,:]<box_max[1]))).squeeze()\n",
        "\n",
        "            # Get segment from untransformed PCL\n",
        "            pcl_segment = pcl_ned[:,mask]\n",
        "\n",
        "        else:\n",
        "            raise ValueError('Wrong bounding box alignment specified: ' + alignment)\n",
        "\n",
        "        return pcl_segment\n",
        "    \n",
        "    def pcl_trafo(self, pcl, trans_oldref=np.zeros(3), trans_newref=np.zeros(3), \n",
        "                  rot=np.zeros(3)):\n",
        "        R = (Rotation.from_euler('x', rot[0]).as_dcm() @\n",
        "             Rotation.from_euler('y', rot[1]).as_dcm() @\n",
        "             Rotation.from_euler('z', rot[2]).as_dcm())\n",
        "\n",
        "        pcl_new = R @ (pcl[:3,:] + trans_oldref.reshape(3,1)) + trans_newref.reshape(3,1)    \n",
        "        return np.vstack((pcl_new, np.ones((1, pcl_new.shape[1]))))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO2TcqNeHu12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f84a24e4-ca62-4820-a6da-1ba7a61acf4a"
      },
      "source": [
        "pcl_loader = PointcloudLoader()\n",
        "pcl_loader.load_ned_trajectory(subset_split=0.01)\n",
        "pcl_loader.load_ned_pointcloud()\n",
        "pcl_loader.generate_submaps(20, 1, width=40)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get start and end time of LIADR measurements...\n",
            "Done!\n",
            "Search for precomputed NED trajectory /content/drive/My Drive/ADL4CV/downloads/oxford_dataset/reference/gps/ned_trajectory_ins_reference.npy...\n",
            "Done!\n",
            "WARNING: We use only the first 1% of the trajectory (1183 measurements)\n",
            "Search for precomputed NED pointcloud /content/drive/My Drive/ADL4CV/downloads/oxford_dataset/reference/lms_front/ned_pointcloud_reference_1percent.npy...\n",
            "Done!\n",
            "Added submap 0\n",
            "Added submap 1\n",
            "End of trajectory reached\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}